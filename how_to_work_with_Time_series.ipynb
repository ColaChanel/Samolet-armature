{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series Analysis - TSA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TSA is a mathematical approach to predicting or forecasting the future pattern of data using historical data arranged in a successive order for a particular time period.\n",
    "\n",
    "Assumption: The only assumption in TSA is that the data is “stationary”, which means that the data is independent of time influence."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Components of TSA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trends — Patterns inside data that reflect the series movement concerning time. The trend can be either linear or nonlinear in nature."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seasonality — Data experience repetitive changes that recur every calendar year."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cyclicity — Data experience changes that are not fixed and beyond the calendar year."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomness — Unknown, Irregular movements or changes in data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different TSA models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TSA has different models like AR, MA, ARIMA, ARMA, etc. Within all of these models, ARIMA is the most frequently used model. Now, why ARIMA is used most frequently? We are not going to discuss these answers there.\n",
    "\n",
    "TSA also provides us with additional information about the data points, but in this article, we are going to understand how to perform a time series analysis in Python."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps involve in TSA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Plot the time series: Look for trends, seasonality, outliers, etc.\n",
    "2. Transform data so that the residuals are stationary: Log transforms or differencing.\n",
    "3. Fit the residuals: AR, MA, etc."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot the time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETS Decomposition\n",
    "result = seasonal_decompose(data['Adj Close**'],model ='multiplicative')\n",
    "# ETS plot \n",
    "result.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Transform data so that the residuals are stationary: Log transforms or differencing."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADF test is being done to check the seasonality of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adfuller(data['Adj Close**'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If P value is 0.32 which is more than 0.05 indicating that our data is not stationary. So we need to transform the data to stationary. Let’s use log transform to target the variable and transform it to stationery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['logarithm_base1'] = np.log2(data['Adj Close**'])\n",
    "# Show the dataframe\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After doing the log transform the P value comes to an acceptable range but if your P value is still not coming under the range then you need to do differencing and check the results until the P value comes under 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d=data.diff(axis = 0, periods = 1)\n",
    "df_d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Fit the residuals: AR, MA, etc."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, there is a library named pmarima. Within this library, there is auto_arima which automatically tunes the parameters(p,d,q) where p is the number of autoregressive terms, d is the number of nonseasonal differences required for stationarity and q is the number of lagged forecast errors in the prediction equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To install the library\n",
    "!pip install pmdarima\n",
    "# Import the library\n",
    "from pmdarima import auto_arima\n",
    "# Ignore harmless warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Fit auto_arima function to dataset\n",
    "stepwise_fit = auto_arima(data['data_d'], start_p = 1, start_q = 1,\n",
    "                          max_p = 3, max_q = 3, m = 12,\n",
    "                          start_P = 0, seasonal = True,\n",
    "                          d = None, D = 1, trace = True,\n",
    "                          error_action ='ignore',   # we don't want to know if an order does not work\n",
    "                          suppress_warnings = True,  # we don't want convergence warnings\n",
    "                          stepwise = True)           # set to stepwise\n",
    "# To print the summary\n",
    "stepwise_fit.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result, we got the optimal model for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train / test sets\n",
    "train = data.iloc[:len(data)-12]\n",
    "test = data.iloc[len(data)-12:] # set one year(12 months) for testing\n",
    "# Fit a SARIMAX(0, 1, 1)x(2, 1, 1, 12) on the training set\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "model = SARIMAX(train['data_d'], \n",
    "                order = (0, 1, 1), \n",
    "                seasonal_order =(2, 1, 1, 12))\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the prediction results and actual results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = len(train)\n",
    "end = len(train) + len(test) - 1\n",
    "# Predictions for one-year against the test set\n",
    "predictions = result.predict(start, end,\n",
    "                             typ = 'levels').rename(\"Predictions\")\n",
    "# plot predictions and actual values\n",
    "predictions.plot(legend = True)\n",
    "test['data_d'].plot(legend = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking for the error. We measure MSE (Mean Square Error) to judge the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load specific evaluation tools\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "# Calculate root mean squared error\n",
    "rmse(test[\"data_d\"], predictions)\n",
    "# Calculate mean squared error\n",
    "mean_squared_error(test[\"data_d\"], predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting future crude oil prices for the next few years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the full dataset\n",
    "model = model = SARIMAX(df['data_d'], \n",
    "                        order = (0, 1, 1), \n",
    "                        seasonal_order =(2, 1, 1, 12))\n",
    "result = model.fit()\n",
    "# Forecast for the next 3 years\n",
    "forecast = result.predict(start = len(df), \n",
    "                          end = (len(df)-1) + 3 * 12, \n",
    "                          typ = 'levels').rename('Forecast')\n",
    "# Plot the forecast values\n",
    "df['data_d'].plot(figsize = (12, 5), legend = True)\n",
    "forecast.plot(legend = True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
